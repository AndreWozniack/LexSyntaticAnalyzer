# Analisador LÃ©xico  
Linguagens Formais e Compiladores

Este projeto Ã© um **analisador lÃ©xico** implementado em Python, baseado em uma **MÃ¡quina de Estados Finitos DeterminÃ­stica (MEFD)**. Ele processa linhas de cÃ³digo e converte lexemas em tokens vÃ¡lidos da linguagem definida.

![Diagrama MEFD](mefd.png)
*MEFD elaborada para fazer a anÃ¡lise lÃ©xica dos lexemas da linguagem*  
Utilizado o software [JFALP](https://www.jflap.org/) para desenvolver essa visualizaÃ§Ã£o

---

## VisÃ£o Geral

O lexer percorre a entrada caractere por caractere e gera uma lista de **tokens** com tipo, valor e posiÃ§Ã£o. Ele reconhece:

- ParÃªnteses: `(` e `)`
- NÃºmeros inteiros e reais (inclusive negativos): `-10`, `2.5`
- Operadores: `+ - * / % ^ |`
- Palavras-chave: `MEM`, `RES`, `IF`, `THEN`, `ELSE`, `FOR`
- Erros lÃ©xicos sÃ£o capturados e registrados como tokens do tipo `ERROR`, com mensagens descritivas

---

## Estrutura

```markdown
â”œâ”€â”€ Lexer.py            # LÃ³gica do analisador lÃ©xico (MEFD)
â”œâ”€â”€ Token.py            # Estrutura do token
â”œâ”€â”€ TokenType.py        # Enum de tipos de token
â”œâ”€â”€ main.py             # Interface de execuÃ§Ã£o
â”œâ”€â”€ mefd.png            # Diagrama da mÃ¡quina de estados
â”œâ”€â”€ test1.txt           # Arquivo de testes simples
â”œâ”€â”€ test2.txt           # Arquivo de testes intermediÃ¡rio
â”œâ”€â”€ test3.txt           # Arquivo de testes com alguns erros propositais
â””â”€â”€ tokens_output.json  # SaÃ­da dos tokens (gerado automaticamente)
```
---

## Como Executar

### 1. PrÃ©-requisitos

- Python 3.8+
- Ambiente virtual (recomendado)

### 2. InstalaÃ§Ã£o

```bash
# Crie um ambiente virtual (opcional, mas recomendado)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows


```
### 3. Rodar o analisador

- NÃ£o hÃ¡ dependÃªncias externas, pronto para usar!
- Com o arquivo de entrada (por exemplo, test1.txt): 

```bash
# Roda o arquivo de teste 1
python main.py --file test1.txt --save-json
```

### Isso irÃ¡:
-	Tokenizar cada linha do arquivo
-	Exibir os tokens ou erros no terminal
-	Salvar a saÃ­da estruturada em tokens_output.json

```json
{
"line": 3,
"tokens": [
{ "value": "abc", "token_class": "ERROR", "row": 3, "column": 1, "error_message": "Unrecognized keyword 'ABC'" },
{ "value": "2", "token_class": "INTEGER_NUMBER", "row": 3, "column": 5 },
{ "value": "+", "token_class": "OPERATOR", "row": 3, "column": 7 }
],
"has_error": true
}
```

## ImplementaÃ§Ã£o baseada em MEFD

Cada tipo de token Ã© reconhecido por uma sequÃªncia de estados da mÃ¡quina MEFD (representada no arquivo mefd.png). A lÃ³gica do autÃ´mato estÃ¡ refletida nas funÃ§Ãµes do Lexer, como:
-	number(): estados q2 â†’ q9 â†’ q10
-	keyword(): estados q3 â†’ q23
-	TransiÃ§Ãµes por current_char() e advance() simulam os arcos da MEFD

---

## ğŸ‘¨â€ğŸ’» Autor

### AndrÃ© Fabricio Wozniack
